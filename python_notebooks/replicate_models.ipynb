{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ivDvY86cjPN","outputId":"59a022b8-1db9-4c5b-b2df-20f0de3c23e3","executionInfo":{"status":"ok","timestamp":1750703163864,"user_tz":240,"elapsed":174356,"user":{"displayName":"Yingying Hao","userId":"13579688415641300767"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: replicate in /usr/local/lib/python3.11/dist-packages (1.0.7)\n","Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from replicate) (24.2)\n","Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.7)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (4.14.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n","ğŸ” Enter your Replicate API Token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n","Mounted at /content/drive\n","ğŸ“„ Processing CIPT Practice Exam.csv with meta-llama-3-8b-instruct\n"]},{"output_type":"stream","name":"stderr","text":["ğŸ’¬ Asking model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [02:34<00:00,  1.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["âœ… Saved to: CIPT Practice Exam-meta-llama-3-8b-instruct-output.csv\n","ğŸ¯ Score: 68 / 90 (75.56%)\n"]}],"source":["# !pip install pandas\n","!pip install replicate\n","\n","# STEP 1: Imports\n","import os\n","import pandas as pd\n","from tqdm import tqdm\n","import replicate\n","from getpass import getpass\n","from google.colab import drive\n","import re\n","\n","# STEP 2: Set up Replicate\n","os.environ[\"REPLICATE_API_TOKEN\"] = getpass(\"ğŸ” Enter your Replicate API Token: \")\n","\n","# STEP 3: Google Drive setup\n","drive.mount('/content/drive', force_remount=True)\n","input_folder = \"/content/drive/MyDrive/research/practice_exams\"\n","output_folder = \"/content/drive/MyDrive/research/replicate_responses\"\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# STEP 4: Models\n","\n","models = {\n","    # \"openai/o4-mini\": \"o4-mini\",\n","    # \"anthropic/claude-3.5-haiku\": \"claude-3.5-haiku\",\n","    # \"openai/o1\": \"o1\",\n","    # \"anthropic/claude-3.7-sonnet\": \"claude-3.7-sonnet\",\n","    # \"meta/meta-llama-3-70b-instruct\": \"meta-llama-3-70b-instruct\",\n","    \"meta/meta-llama-3-8b-instruct\": \"meta-llama-3-8b-instruct\",\n","    # \"deepseek-ai/deepseek-r1\": \"deepseek-r1\",\n","    # \"google-deepmind/gemma-7b-it\": \"gemma-7b-it\",\n","    # \"google-deepmind/gemma-2b-it\": \"gemma-2b-it\",\n","    # \"lucataco/qwen1.5-72b\": \"qwen1.5-72b\",\n","    # \"lucataco/qwen2.5-omni-7b\": \"qwen2.5-omni-7b\",\n","\n","\n","}\n","\n","# STEP 5: Exams\n","exam_files = [\n","    # \"CIPPUS Practice Exam.csv\"\n","\n","    #  \"AIGP Practice Exam.csv\",\n","    # \"CIPM Practice Exam.csv\",\n","    \"CIPT Practice Exam.csv\"\n","]\n","\n","\n","# STEP 6: Helpers\n","def build_prompt(row, answer_columns):\n","    lines = []\n","\n","    if 'scenario' in row and pd.notna(row['scenario']):\n","        lines.append(f\"Context:\\n{row['scenario']}\\n\")\n","\n","    lines.append(f\"Question:\\n{row['question']}\\n\")\n","    lines.append(\"Choices:\")\n","    for i, col in enumerate(answer_columns):\n","        lines.append(f\"{chr(65 + i)}. {row[col]}\")\n","\n","    lines.append(\n","        \"\\nYou are a certified U.S. privacy professional taking a high-stakes multiple-choice exam (such as the AIGP, CIPP/US, or CIPT).\\n\"\n","        \"Read the question and choices carefully. Use your knowledge of U.S. privacy laws (e.g., GDPR, CCPA, HIPAA, etc.), data governance best practices, and legal reasoning.\\n\\n\"\n","        \"Eliminate clearly incorrect choices if possible. Choose the BEST answer, even if more than one seems partially correct.\\n\\n\"\n","        \"Respond only in the following exact format:\\n\"\n","        \"Final Answer: <A/B/C/D>\\n\"\n","        \"Explanation: <A concise justification, under 150 words. Reference relevant laws or best practices.>\\n\\n\"\n","        \"Do not explain all four choicesâ€”just support your final choice.\"\n","    )\n","    return \"\\n\".join(lines)\n","\n","def query_model(model_id, prompt):\n","    try:\n","        output = replicate.run(model_id, input={\"prompt\": prompt})\n","        return \"\".join(output) if isinstance(output, list) else output\n","    except Exception as e:\n","        print(f\"âš ï¸ Model query failed: {e}\")\n","        return \"\"\n","\n","def extract_by_content_match(response, answer_choices):\n","    response = response.lower()\n","    best_match = \"\"\n","    best_score = 0\n","\n","    for letter, text in answer_choices.items():\n","        if not isinstance(text, str):\n","            continue\n","        overlap = len(set(text.lower().split()) & set(response.split()))\n","        if overlap > best_score:\n","            best_score = overlap\n","            best_match = letter\n","\n","    return best_match.upper()\n","\n","def extract_answer_letter(response, answer_choices=None):\n","    if not isinstance(response, str):\n","        return \"\"\n","\n","    # Match \"Final Answer: A\"\n","    match = re.search(r\"final answer\\s*[:\\-]?\\s*([A-D])\\b\", response, re.IGNORECASE)\n","    if match:\n","        return match.group(1).upper()\n","\n","    lines = response.strip().splitlines()\n","    if not lines:\n","        return \"\"\n","\n","    for line in lines:\n","        if re.fullmatch(r\"[A-Da-d]\", line.strip()):\n","            return line.strip().upper()\n","\n","    match = re.search(r\"\\b(correct|best|answer)\\s*(is|:)?\\s*([A-D])\\b\", response, re.IGNORECASE)\n","    if match:\n","        return match.group(3).upper()\n","\n","    match = re.match(r\"^\\s*([A-D])[\\.:]?\\s\", lines[0])\n","    if match:\n","        return match.group(1).upper()\n","\n","    if answer_choices:\n","        return extract_by_content_match(response, answer_choices)\n","\n","    return \"\"\n","\n","\n","def evaluate_response(model_letter, correct_letter, choices, response):\n","    model_letter = model_letter.strip().upper()\n","    correct_letter = correct_letter.strip().upper()\n","\n","    if model_letter == correct_letter:\n","        return 1\n","\n","    correct_text = choices.get(correct_letter, \"\").strip().lower()\n","    if correct_text and correct_text in response.lower():\n","        return 1\n","\n","    return 0\n","\n","# STEP 7: Main process\n","def process_exam(model_id, model_name, file_name):\n","    print(f\"ğŸ“„ Processing {file_name} with {model_name}\")\n","\n","    file_path = os.path.join(input_folder, file_name)\n","    df = pd.read_csv(file_path)\n","\n","    answer_cols = sorted([col for col in df.columns if col.lower().startswith(\"answer\")])\n","    required = ['question', 'correct answer'] + answer_cols\n","    if not all(col in df.columns for col in required):\n","        raise ValueError(f\"Missing required columns in {file_name}\")\n","\n","    optional_cols = ['scenario'] if 'scenario' in df.columns else []\n","    df = df[required + optional_cols]\n","    df = df.dropna(subset=['question'])\n","\n","    results = []\n","    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"ğŸ’¬ Asking model\"):\n","        prompt = build_prompt(row, answer_cols)\n","        response = query_model(model_id, prompt)\n","        answer_choices = {chr(65 + i): row[col] for i, col in enumerate(answer_cols)}\n","        model_letter = extract_answer_letter(response, answer_choices)\n","        score = evaluate_response(model_letter, row['correct answer'], answer_choices, response)\n","\n","        result = {\n","            \"question\": row['question'],\n","            \"scenario\": row.get('scenario', \"\"),\n","            \"correct answer\": row['correct answer'],\n","            \"model answer\": model_letter,\n","            \"score\": score,\n","            \"response\": response,\n","            **{col: row[col] for col in answer_cols}\n","        }\n","        results.append(result)\n","\n","    df_out = pd.DataFrame(results)\n","\n","    # Reorder columns for output\n","    columns_order = ['question']\n","    if 'scenario' in df_out.columns:\n","        columns_order.append('scenario')\n","    columns_order += answer_cols + ['correct answer', 'model answer', 'score', 'response']\n","    df_out = df_out[columns_order]\n","\n","      # Add total score row with percentage\n","    total_score = df_out['score'].sum()\n","    total_questions = len(df_out)  # includes TOTAL row, so subtract 1 later\n","    percentage = (total_score / (total_questions - 1)) * 100 if total_questions > 1 else 0\n","\n","    score_row = {col: \"\" for col in df_out.columns}\n","    score_row['question'] = \"TOTAL SCORE\"\n","    score_row['score'] = f\"{total_score} / {total_questions - 1} ({percentage:.1f}%)\"\n","\n","    df_out = pd.concat([df_out, pd.DataFrame([score_row])], ignore_index=True)\n","\n","    # Save\n","    output_file = f\"{file_name.split('.')[0]}-{model_name}-output.csv\"\n","    df_out.to_csv(os.path.join(output_folder, output_file), index=False)\n","\n","    print(f\"âœ… Saved to: {output_file}\")\n","    print(f\"ğŸ¯ Score: {total_score} / {len(df_out) - 1} ({(total_score / (len(df_out) - 1)) * 100:.2f}%)\")\n","\n","# STEP 8: Run\n","for model_id, model_name in models.items():\n","    for exam_file in exam_files:\n","        process_exam(model_id, model_name, exam_file)"]}]}