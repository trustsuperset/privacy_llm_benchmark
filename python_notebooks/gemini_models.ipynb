{"cells":[{"cell_type":"code","source":["# STEP 1: Install packages\n","!pip install google-generativeai tqdm pandas"],"metadata":{"id":"hbfRAJD723Nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# STEP 2: Imports\n","import os\n","import google.generativeai as genai\n","import pandas as pd\n","from tqdm import tqdm\n","from google.colab import drive\n","import re"],"metadata":{"id":"3-xiyIUS24f6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 3: Authenticate Gemini (replace the api_key)\n","genai.configure(api_key=\"\")"],"metadata":{"id":"AQZDgbj926a_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 4: Load Gemini 1.5 Pro or 2.5 Pro if available\n","model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n","# model = genai.GenerativeModel(model_name=\"gemini-2.5-pro\")"],"metadata":{"id":"KpBGJ1tM3AHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 5: Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","input_folder = \"/content/drive/MyDrive/research/practice_exams\"\n","output_folder = \"/content/drive/MyDrive/research/gen_responses\"\n","os.makedirs(output_folder, exist_ok=True)"],"metadata":{"id":"oR4Nxt-B3CqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 6: Exam files (FIXED commas)\n","exam_files = [\n","    # \"CIPT Practice Exam.csv\",\n","    # \"CIPPUS Practice Exam.csv\",\n","    # \"AIGP Practice Exam.csv\",\n","    \"CIPM Practice Exam.csv\",\n","]"],"metadata":{"id":"VXc2EbZ13IBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 7: Prompt builder\n","def build_prompt(row, answer_columns):\n","    lines = []\n","\n","    if 'scenario' in row and pd.notna(row['scenario']):\n","        lines.append(f\"Context:\\n{row['scenario']}\\n\")\n","\n","    lines.append(f\"Question:\\n{row['question']}\\n\")\n","    lines.append(\"Choices:\")\n","    for i, col in enumerate(answer_columns):\n","        lines.append(f\"{chr(65 + i)}. {row[col]}\")\n","\n","    lines.append(\n","        \"\\nYou are a certified U.S. privacy professional taking a high-stakes multiple-choice exam (such as the AIGP, CIPP/US, or CIPT).\\n\"\n","        \"Read the question and choices carefully. Use your knowledge of U.S. privacy laws (e.g., GDPR, CCPA, HIPAA, etc.), data governance best practices, and legal reasoning.\\n\\n\"\n","        \"Eliminate clearly incorrect choices if possible. Choose the BEST answer, even if more than one seems partially correct.\\n\\n\"\n","        \"Respond only in the following exact format:\\n\"\n","        \"Final Answer: <A/B/C/D>\\n\"\n","        \"Explanation: <A concise justification, under 150 words. Reference relevant laws or best practices.>\\n\\n\"\n","        \"Do not explain all four choices—just support your final choice.\"\n","    )\n","    return \"\\n\".join(lines)"],"metadata":{"id":"V4F9sq4Z3KuI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 8: Gemini Query with error handling\n","def query_model_gemini(prompt):\n","    try:\n","        response = model.generate_content(prompt)\n","        return response.text if response else \"\"\n","    except Exception as e:\n","        print(f\"⚠️ Gemini query failed: {e}\")\n","        return f\"ERROR: {e}\""],"metadata":{"id":"Yl3BDfFd3Nq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STEP 9: Extract answer letter\n","def extract_answer_letter(response, answer_choices=None):\n","    if not isinstance(response, str):\n","        return \"\"\n","\n","    match = re.search(r\"final answer\\s*[:\\-]?\\s*([A-D])\\b\", response, re.IGNORECASE)\n","    if match:\n","        return match.group(1).upper()\n","\n","    lines = response.strip().splitlines()\n","    if not lines:\n","        return \"\"\n","\n","    for line in lines:\n","        if re.fullmatch(r\"[A-Da-d]\", line.strip()):\n","            return line.strip().upper()\n","\n","    match = re.search(r\"\\b(correct|best|answer)\\s*(is|:)?\\s*([A-D])\\b\", response, re.IGNORECASE)\n","    if match:\n","        return match.group(3).upper()\n","\n","    match = re.match(r\"^\\s*([A-D])[\\.:]?\\s\", lines[0])\n","    if match:\n","        return match.group(1).upper()\n","\n","    return \"\""],"metadata":{"id":"cg7FQ_Q23QI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# STEP 10: Evaluate response\n","def evaluate_response(model_letter, correct_letter, choices, response):\n","    model_letter = model_letter.strip().upper()\n","    correct_letter = correct_letter.strip().upper()\n","\n","    if model_letter == correct_letter:\n","        return 1\n","\n","    correct_text = choices.get(correct_letter, \"\").strip().lower()\n","    if correct_text and correct_text in response.lower():\n","        return 1\n","\n","    return 0"],"metadata":{"id":"69zvtVXj3Thh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AdFkfWuD9DN9"},"outputs":[],"source":["# STEP 11: Main loop\n","for exam_file in exam_files:\n","    print(f\"📄 Processing {exam_file} with Gemini 1.5 Pro\")\n","\n","    file_path = os.path.join(input_folder, exam_file)\n","    df = pd.read_csv(file_path)\n","\n","    # Check required columns\n","    answer_cols = sorted([col for col in df.columns if col.lower().startswith(\"answer\")])\n","    required_cols = ['question', 'correct answer'] + answer_cols\n","    missing_cols = [col for col in required_cols if col not in df.columns]\n","\n","    if missing_cols:\n","        print(f\"⚠️ Skipping {exam_file} - missing columns: {missing_cols}\")\n","        continue\n","\n","    df = df.dropna(subset=['question'])\n","\n","    results = []\n","    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"💬 Asking Gemini\"):\n","        prompt = build_prompt(row, answer_cols)\n","        response = query_model_gemini(prompt)\n","        answer_choices = {chr(65 + i): row[col] for i, col in enumerate(answer_cols)}\n","        model_letter = extract_answer_letter(response, answer_choices)\n","        score = evaluate_response(model_letter, row['correct answer'], answer_choices, response)\n","\n","        result = {\n","            \"question\": row['question'],\n","            \"scenario\": row.get('scenario', \"\"),\n","            \"correct answer\": row['correct answer'],\n","            \"model answer\": model_letter,\n","            \"score\": score,\n","            \"response\": response,\n","            **{col: row[col] for col in answer_cols}\n","        }\n","        results.append(result)\n","\n","    df_out = pd.DataFrame(results)\n","\n","    # Add total score\n","    total_score = df_out['score'].sum()\n","    total_questions = len(df_out)\n","    percentage = (total_score / total_questions) * 100 if total_questions > 0 else 0\n","\n","    total_row = {col: \"\" for col in df_out.columns}\n","    total_row['question'] = \"TOTAL SCORE\"\n","    total_row['score'] = f\"{total_score}/{total_questions} ({percentage:.1f}%)\"\n","    df_out = pd.concat([df_out, pd.DataFrame([total_row])], ignore_index=True)\n","\n","    output_file = f\"{exam_file.split('.')[0]}-gemini-1.5-pro-output.csv\"\n","    df_out.to_csv(os.path.join(output_folder, output_file), index=False)\n","    print(f\"✅ Saved to {output_file}\")\n","    print(f\"🎯 Score: {total_score}/{total_questions} ({percentage:.1f}%)\")\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjia6780xUl+M5rOwbgvEI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}